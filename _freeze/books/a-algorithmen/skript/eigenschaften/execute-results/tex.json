{
  "hash": "ffdc22ec7aa840f9a2d9bae62debecbb",
  "result": {
    "engine": "jupyter",
    "markdown": "# Eigenschaften\n\n\n\n## Terminiertheit\n\nTerminiertheit bedeutet, dass ein Algorithmus nach endlich vielen Schritten anhält, oder er bricht kontrolliert ab. Einfache Beispiele:\n\n* Addition zweier Dezimalzahlen\n* Summe der ersten N natürlichen Zahlen\n\nAllerdings kann die Terminiertheit nicht für alle Algerithmen gezeigt werden. Das [Halteproblem](https://de.wikipedia.org/wiki/Halteproblem) besagt, dass es gibt keinen Verfahren gibt, welches immer zutreffend sagen kann, ob der Algorithmus für die Eingabe terminiert. Hierzu kann das [Collatz-Problem](https://de.wikipedia.org/wiki/Collatz-Problem) als Beispiel herangezogen werden. \n\nDie Zahlenfolge wird wie folgt konstruiert: \n\n* beginne mit irgendeiner natürlichen Zahl $\\mathsf n_0 > 0$\n* ist $\\mathsf n_i$ gerade so ist $\\mathsf n_{i+1} = n_i/2$\n* ist $\\mathsf n_i$ ungerade so ist $\\mathsf n_{i+1} = 3n_i + 1$\n* endet bei $\\mathsf n_i = 1$\n\nCollatz-Vermutung: Jede so konstruierte Zahlenfolge mündet in den Zyklus 4, 2, 1, egal, mit welcher natürlichen Zahl man beginnt. Bisher unbewiesen.\n\n## Determiniertheit\n\nEin deterministischer Algorithmus ist ein Algorithmus, bei dem nur definierte und reproduzierbare Zustände auftreten. Die Ergebnisse des Algorithmus sind somit immer reproduzierbar. Beispiele hierfür:\n\n* Addition ganzer Zahlen\n* Selectionsort\n* Collatz-Sequenz\n\n## Effizienz\n\nDie Effizienz eines Algorithmus ist nicht strikt definiert und kann folgende Aspekte umfassen: \n\n* Laufzeit\n* Speicheraufwand\n* Energieverbrauch\n\nBei bestimmten Anwendungen sind entsprechende Eigenschaften notwendig:\n\n* Speicheraufwand bei *Big Data*, also riesige Datenmengen, z.B. in der Bioinformatik\n* Laufzeit bei Echtzeitanwendung, z.B. Flugzeugsteuerung, Fußgängerdynamik\n\n## Komplexität\n\nBei der Analyse von Algorithmen, gilt es die Komplexiät zu bestimmen, welche ein Maß für den Aufwand darstellt. Dabei wird nach einer Aufwandfunktion $\\mathsf f(n)$ gesucht, welche von der Problemgröße $\\mathsf n$ abhängt. Beispiel für eine Problemgröße:\n\n* Anzahl der Summanden bei einer Summe \n* Anzahl der zu sortierenden Zahlen\n\nMeist wird dabei die Bestimmung auf eine asymptotische Analyse, d.h. eine einfache Vergleichsfunktion $\\mathsf g(n)$ mit $\\mathsf n \\rightarrow \\infty$, reduziert. Dabei beschränkt $\\mathsf g(n)$ das Wachstum von $\\mathsf f(n)$.\n\nDie Funktion $\\mathsf g(n)$ wird oft durch ein $\\mathsf \\mathcal{O}$ gekennzeichnet und gibt so eine möglichst einfache Vergleichsfunktion an. Beispiele:\n\n* $\\mathsf f_1(n) = n^4 + 5n^2 - 10 \\approx \\mathcal{O}(n^4) = g_1(n)$ \n* $\\mathsf f_2(n) = 2^{n+1} \\approx \\mathcal{O}(2^n) = g_2(n)$ \n\n::: {.cell tags='[\"remove_input\"]' execution_count=2}\n``` {.python .cell-code}\nx = np.linspace(1,100,500)\nf = x**4 - 60*x**2 + 1000\ng = x**4\n\nplt.plot(x,f, label=\"$f_1(n)$\")\nplt.plot(x,g, label='$g_1(n)$')\nplt.xlabel('n')\nplt.legend()\nplt.xscale('log')\nplt.yscale('log')\nplt.grid()\nplt.savefig('00-bilder/komplexitaet.svg')\nplt.close()\n```\n:::\n\n\n![Komplexität eines Algorithmus durch Vergleich einer Aufwandfunktion mit einer Vergleichsfunktion](00-bilder/komplexitaet.svg)\n\nUm sich ein besseres Bild zu den Auswirkungen hoher Kompexitäten zu machen, sei folgendes Beispiel gegeben.\n\n* ein Berechnungsschritt (unabhängig von der Problemgröße $\\mathsf n$) sei z.B. 1 s lang\n* das $\\mathsf n$ sei beispielsweise 1000\n\nDamit ergeben sich folgende (asymptotische) Abschätzungen der Laufzeit:\n\n* $\\mathsf \\mathcal{O}(n)$: 10<sup>3</sup> s ≈ 1 h \n* $\\mathsf \\mathcal{O}(n^2)$: 10<sup>6</sup> s ≈ 11 d \n* $\\mathsf \\mathcal{O}(n^3)$: 10<sup>9</sup> s ≈ 31 a \n* $\\mathsf \\mathcal{O}(2^n)$: 2<sup>1000</sup> s ≈ ...\n\n### Komplexität Selectionsort\n\nDie Kompexität dieses Verfahrens kann leicht abgeschätzt werden. Bei jedem Durchlauf wir das Minimum / Maximum gesucht, was anfangs $\\mathsf n$ Operationen benötigt. Beim nächsten Durchlauf sind es nur noch $\\mathsf n − 1$ Operationen und so weiter. In der Summe sind es also \n\n$$ \\mathsf f(n) = \\sum_{i=0}^n i = \\frac{n(n-1)}{2} \\approx \\mathcal{O}(n^2) $$\n\nDamit hat der Selectionsort eine Komplexität von $\\mathsf \\mathcal{O}(n^2)$. Die folgende Abbildung verdeutlicht dies nochmals.\n\n::: {.cell jupyter='{\"source_hidden\":true}' tags='[\"remove_input\",\"remove_cell\"]' execution_count=3}\n``` {.python .cell-code}\ndef sort_sel(A):\n    cnt = 0\n    n = len(A)\n    for i in range(n):\n        mv = A[i]\n        mi = i\n        for j in range(i, n):\n            cnt += 1\n            if A[j] < mv:\n                mv = A[j]\n                mi = j\n#                 cnt += 1\n        A[mi] = A[i]\n        A[i] = mv\n#         cnt += 1\n    return cnt\n\ndef sort_bubble(A):\n    cnt = 0\n    n = len(A)\n    for i in range(n):\n        swapped = False\n        for j in range(0, n-i-1):\n#             print(j, 0, n-i)\n            cnt += 1\n            if A[j+1] < A[j]:\n                mv = A[j]\n                A[j] = A[j+1]\n                A[j+1] = mv\n#                 cnt += 3\n                swapped = True\n        if swapped == False:\n#             print('no swap', i)\n            return cnt\n    return cnt\n```\n:::\n\n\n::: {.cell jupyter='{\"source_hidden\":true}' tags='[\"remove_cell\"]' execution_count=4}\n``` {.python .cell-code}\ndef analyse_sorting(sort_fnk, non_rand_p = 0.0, reps = 100):\n    n_max = 100001\n    rand_A = np.random.randint(0, high=n_max // 2, size=10*n_max)\n\n    def time_sorting(n):\n        i = np.random.randint(0, n_max, size=1)[0]\n        A = np.copy(rand_A[i:i+n])\n        non_rand_i = np.linspace(0, n-1, int(n*non_rand_p), dtype=np.int32)\n#         print(n, len(non_rand_i))\n        A[non_rand_i] = np.linspace(0, n_max//2, len(non_rand_i), dtype=np.int32)\n#         print(A)\n        return sort_fnk(A)\n\n    res_min = []\n    res_avg = []\n    res_max = []\n    ns = []\n\n# for n in range(1, 10, 1):\n#     print(n)\n#     res = []\n#     for r in range(reps):\n#         res.append(time_sorting(n))\n#     ns.append(n)\n#     res_min.append(np.min(res))\n#     res_max.append(np.max(res))\n#     res_avg.append(np.average(res))\n\n    for n in range(10, 101, 10):\n#         print(n)\n        res = []\n        for r in range(reps):\n            res.append(time_sorting(n))\n        ns.append(n)\n        res_min.append(np.min(res))\n        res_max.append(np.max(res))\n        res_avg.append(np.average(res))\n        print(n, np.average(res))\n\n#     for n in range(100, 1101, 100):\n#         print(n)\n#         res = []\n#         for r in range(reps):\n#             res.append(time_sorting(n))\n#         ns.append(n)\n#         res_min.append(np.min(res))\n#         res_max.append(np.max(res))\n#         res_avg.append(np.average(res))\n    \n    return np.array(ns), np.array(res_min), np.array(res_avg), np.array(res_max)\n```\n:::\n\n\n::: {.cell tags='[\"remove_cell\"]' execution_count=5}\n``` {.python .cell-code}\ndef plot_sorting(res, label, avg_only = False, title=None):\n    \n    ns, y1, y2, y3 = res\n    \n    if not avg_only:\n        plt.plot(ns, y1, color='C0', lw=0.5)\n        plt.plot(ns, y3, color='C0', lw=0.5, label='Min / Max')\n        plt.fill_between(ns, y1, y3, alpha=0.3, color='C0')\n    plt.plot(ns, y2, color='C1', label='Mittelwert')\n\n    yi1 = 1e0 * ns\n    yi2 = 1e0 * ns**2\n\n    plt.plot(ns, yi1, ls=':', color='C2', label='Hilfslinien, $\\mathcal{O}(n)$, $\\mathcal{O}(n^2)$')\n    plt.plot(ns, yi2, ls=':', color='C2')\n\n    plt.xscale('log')\n    plt.yscale('log')\n\n    plt.xlabel('Länge der Werteliste')\n    plt.ylabel('Durchgeführte Operationen')\n    plt.grid()\n    plt.legend()\n    if title:\n        plt.title(title)\n    plt.savefig('00-bilder/{}.svg'.format(label))\n    plt.close()\n```\n:::\n\n\n::: {.cell jupyter='{\"outputs_hidden\":true,\"source_hidden\":true}' tags='[\"remove_cell\"]' execution_count=6}\n``` {.python .cell-code}\nres1 = analyse_sorting(sort_bubble, non_rand_p = 0.0, reps = 1000)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n10 41.928\n20 180.692\n30 418.619\n40 758.184\n50 1195.148\n60 1734.672\n70 2370.677\n80 3107.193\n90 3937.044\n100 4876.876\n```\n:::\n:::\n\n\n::: {.cell tags='[\"remove_input\"]' execution_count=7}\n``` {.python .cell-code}\nplot_sorting(res1, 'sort_selection', avg_only = True)\n```\n:::\n\n\n![Abschätzung der Koplexität des Selectionsort-Algorithmus](00-bilder/sort_selection.svg)\n\n### Komplexität Bubblesort\n\nDie Komplexität des Bubblesort muss unterschieden werden in den günstigsten Fall (best case), den ungünstigsten Fall (worst case) und einem durchschnittlichen Fall (average case):\n\n* best case: $\\mathsf \\mathcal{O} (n)$\n* worst case: $\\mathsf \\mathcal{O} (n^2)$ \n* average case: $\\mathsf \\mathcal{O} (n^2)$\n\nDer best case ergibt sich zum Beispiel, falls die Eingabeliste bereits sortiert ist, da der Algorithmus nur einmal durch die Liste gehen muss, entsprechend n-Mal. Folgende Abbildung verdeutlicht die Anzahl der durchgeführten Operationen im Falle einer vollständig zufälligen Liste und einer, bei welcher 95% der Werte bereits sortiert ist. Dabei wurden für jedes $\\mathsf n$ jeweils 10000 Listen sortiert. Es ist der Mittelwert und die minimalen und maximalen Operationen dargestellt.\n\n::: {.cell tags='[\"remove_cell\"]' execution_count=8}\n``` {.python .cell-code}\nres2 = analyse_sorting(sort_bubble, non_rand_p = 0.0, reps = 10000)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n10 42.0047\n20 181.1159\n30 419.1297\n40 756.9536\n50 1194.2213\n60 1730.6822\n70 2367.6256\n80 3104.3147\n90 3941.8895\n100 4878.7989\n```\n:::\n:::\n\n\n::: {.cell tags='[\"remove_input\"]' execution_count=9}\n``` {.python .cell-code}\nplot_sorting(res2, 'sort_bubble_p000', title='0\\% vorsortiert')\n```\n:::\n\n\n![Abschätzung der Koplexität des Bubblesort-Algorithmus ohne Vorsortierung](00-bilder/sort_bubble_p000.svg)\n\n::: {.cell tags='[\"remove_cell\"]' execution_count=10}\n``` {.python .cell-code}\nres3 = analyse_sorting(sort_bubble, non_rand_p = 0.95, reps = 10000)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n10 29.9371\n20 126.0979\n30 303.8814\n40 545.9256\n50 907.2712\n60 1301.9906\n70 1865.8567\n80 2437.5558\n90 3209.365\n100 3954.0069\n```\n:::\n:::\n\n\n::: {.cell tags='[\"remove_input\"]' execution_count=11}\n``` {.python .cell-code}\nplot_sorting(res3, 'sort_bubble_p095', title='95\\% vorsortiert')\n```\n:::\n\n\n![Abschätzung der Koplexität des Bubblesort-Algorithmus mit einer 95%-igen Vorsortierung](00-bilder/sort_bubble_p095.svg)\n\n",
    "supporting": [
      "eigenschaften_files/figure-pdf"
    ],
    "filters": []
  }
}