{
  "hash": "2f334b1d943b82ec1231f98ff9284e5b",
  "result": {
    "engine": "jupyter",
    "markdown": "# Numerische Algorithmen\n\n\n\n## Newton-Raphson-Verfahren\n\nEines der einfachsten und auch ältesten Verfahren zur Suche von Nullstellen von \nFunktionen ist das [Newton-Raphson-Verfahren](https://de.wikipedia.org/wiki/Newtonverfahren), \nwelches bereits im 17-ten Jahrhundert entwickelt und eingestetzt wurde.\n\n### Anwendungen\nDas Finden von Nullstellen ist die Grundlage für viele Verfahren, welche z.B. für \n\n* das Lösen von nicht-linearen Gleichungen, \n* das Finden von Extremwerten, oder\n* Optimierungsverfahren\n\neingesetzt werden kann.\n \n\n### Grundidee \nDie Grundidee beruht auf einer iterativen Suche der Nullstelle $\\mathsf x_{ns}$ \neiner stetig differenzierbaren Funktion $\\mathsf f(x)$ mit Hilfe der ersten Ableitung \n$\\mathsf f'(x)$. Durch das Anlegen von Tangenten an die aktuelle Näherung der Nullstelle \n$\\mathsf x_i$ kann die nächste Näherung bestimmt werden. \n\nBei gegebenen Startwert, $\\mathsf x_0$ für den ersten Iterationsschritt ($\\mathsf i=0$), \nkönnen die folgenden Näherungen durch\n\n$$\\mathsf x_{i+1} = x_i - \\frac{f(x_i)}{f'(x_i)} $$\n\nberechnet werden. Dabei bestimmt die Wahl des Startwerts, welche der ggf. \nmehreren Nullstellen gefunden wird. \n\n### Beispiel 1\n\nGegeben ist die Funktion $\\mathsf f(x) = x^2 - 1$. Die Ableitung ist gegeben durch \n$\\mathsf f'(x) = 2x$ und die Nullstellen lauten $\\mathsf x_{ns} = \\{-1, 1\\}$.\n\nBei einem Startwert von $\\mathsf x_0 = 0.3$ führt zu folgender Iteration:\n\n::: {#9ac4478a .cell tags='[\"remove_input\"]' execution_count=2}\n\n::: {.cell-output .cell-output-stdout}\n```\nStartwert x_0 = 0.3000\n\nIterationsschritt i =  1, x_i = 0.3000\n   f(x_i)  = -0.9100\n   fp(x_i) = 0.6000\n   x_(i+1) = 1.8167\n\nIterationsschritt i =  2, x_i = 1.8167\n   f(x_i)  = 2.3003\n   fp(x_i) = 3.6333\n   x_(i+1) = 1.1836\n\nIterationsschritt i =  3, x_i = 1.1836\n   f(x_i)  = 0.4008\n   fp(x_i) = 2.3671\n   x_(i+1) = 1.0142\n\nIterationsschritt i =  4, x_i = 1.0142\n   f(x_i)  = 0.0287\n   fp(x_i) = 2.0285\n   x_(i+1) = 1.0001\n\n\nEndergebnis nach 5 Iterationen: x_(ns) = 1.0001\n```\n:::\n:::\n\n\n::: {#35a3d3d2 .cell tags='[\"remove_cell\"]' execution_count=3}\n\n::: {.cell-output .cell-output-display}\n```\n<Figure size 672x480 with 0 Axes>\n```\n:::\n:::\n\n\n\n\n![Newton-Verfahren, Beispiel 1](00-bilder/newton_bsp1.svg)\n\n::: {.panel-tabset}\n\n## Schritt 0\n![](00-bilder/newton_bsp1_step_00.svg)\n\n## Schritt 1\n![](00-bilder/newton_bsp1_step_01.svg)\n\n## Schritt 2\n![](00-bilder/newton_bsp1_step_02.svg)\n\n## Schritt 3\n![](00-bilder/newton_bsp1_step_03.svg)\n\n## Schritt 4\n![](00-bilder/newton_bsp1_step_04.svg)\n:::\n\n### Beispiel 2\n\nGegeben ist die Funktion $\\mathsf f(x) = \\sin(x) - 0.5$ mit der Ableitung $\\mathsf f'(x) = \\cos(x)$.\n\n::: {#b000a134 .cell tags='[\"remove_input\"]' execution_count=5}\n``` {.python .cell-code}\ndef f(x):\n    return np.sin(x) -0.5\ndef fp(x):\n    return np.cos(x)\n\nx0 = 1.3\n\nprint('Startwert x_0 = {:.4f}'.format(x0))\nprint()\n\nn = 5\nxi = [x0]\nfor i in range(1,n):\n    xp = xi[i-1]\n    xn = xp - (f(xp)/fp(xp))\n    \n    print('Iterationsschritt i = {:2d}, x_i = {:.4f}'.format(i, xp))\n    print('   f(x_i)  = {:.4f}'.format(f(xp)))\n    print('   fp(x_i) = {:.4f}'.format(fp(xp)))\n    print('   x_(i+1) = {:.4f}'.format(xn))\n    print()\n    \n    xi.append(xn)\n    \nprint()\nprint('Endergebnis nach {} Iterationen: x_(ns) = {:.4f}'.format(n, xi[-1]))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStartwert x_0 = 1.3000\n\nIterationsschritt i =  1, x_i = 1.3000\n   f(x_i)  = 0.4636\n   fp(x_i) = 0.2675\n   x_(i+1) = -0.4329\n\nIterationsschritt i =  2, x_i = -0.4329\n   f(x_i)  = -0.9195\n   fp(x_i) = 0.9077\n   x_(i+1) = 0.5801\n\nIterationsschritt i =  3, x_i = 0.5801\n   f(x_i)  = 0.0481\n   fp(x_i) = 0.8364\n   x_(i+1) = 0.5226\n\nIterationsschritt i =  4, x_i = 0.5226\n   f(x_i)  = -0.0009\n   fp(x_i) = 0.8665\n   x_(i+1) = 0.5236\n\n\nEndergebnis nach 5 Iterationen: x_(ns) = 0.5236\n```\n:::\n:::\n\n\n\n\n\n\n![Newton-Verfahren, Beispiel 2](00-bilder/newton_bsp2.svg)\n\n::: {.panel-tabset}\n\n## Schritt 0\n![](00-bilder/newton_bsp2_step_00.svg)\n\n## Schritt 1\n![](00-bilder/newton_bsp2_step_01.svg)\n\n## Schritt 2\n![](00-bilder/newton_bsp2_step_02.svg)\n\n## Schritt 3\n![](00-bilder/newton_bsp2_step_03.svg)\n\n## Schritt 4\n![](00-bilder/newton_bsp2_step_04.svg)\n:::\n\n## Euler-Verfahren\n\nDas explizite [Euler-Verfahren](https://de.wikipedia.org/wiki/Explizites_Euler-Verfahren) \nist ein einfacher Algorithmus zur Bestimmung von Näherungslösungen von gewöhnlichen \nDifferentialgleichungen, insbesondere Anfangswertprobleme. Das Verfahren wird hier \nanhand einer linearen Differentialgleichung 1. Ordnung demonstiert, hier ist \n$\\mathsf y = y(t)$ eine Funktion der Zeit $\\mathsf t$. Die Differentialgleichung lautet\n\n$$\\dot y(t) + a(t)y(t) + b(t) = 0$$\n\nMit einem vorgegebenen Anfangswert $\\mathsf y_0 = y(t_0)$ kann die Näherungslösung \niterativ bis zur gewünschten Endzeit $\\mathsf t_e$ bestimmt werden. Dazu muss das \nbetrachtete Zeitintervall $\\mathsf[t_0, t_e]$ in $\\mathsf n_t$ Teilintervalle aufgeteilt \nwerden. Die Länge eines Teilintervalls ist \n\n$$\\mathsf \\Delta t = \\frac{t_e - t_0}{n_t}\\quad .$$ \n\nDas iterative Verfahren beschreibt die Bestimmung der Lösung im nächsten \nZeitinterval $\\mathsf t_{i+1}$\n\n$$\\mathsf  y(t_{i+1}) = y(t_i) - \\Delta t \\big(a(t_i)y(t_i) + b(t_i)\\big)\\quad .$$\n\n### Beispiel 1\n\nMit $\\mathsf a(t) = 1$, $\\mathsf b(t) = 0$ und einem Anfangswert von $\\mathsf y_0 = 1$.\n\n",
    "supporting": [
      "numerische_algorithmen_files"
    ],
    "filters": [],
    "includes": {}
  }
}