{
  "hash": "f7860b59a488f49d253eb101101648ab",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Datenanalyse mit NumPy und Matplotlib – Von der Datei zur Erkenntnis\"\nformat:\n  html:\n    toc: true\n    code-fold: false\n    code-overflow: wrap\njupyter: python3\n---\n\n\n\n\n\n\n# Einleitung\n\nIn dieser Einheit lernst du, wie man reale Messdaten – etwa aus Experimenten oder Ingenieurprojekten – mit NumPy und Matplotlib verarbeitet und analysiert. Der Fokus liegt dabei auf einem praxisnahen Umgang mit Daten im CSV-Format.\n\nWir arbeiten vollständig ohne Pandas, um die Grundlagen der Array-Verarbeitung besser nachvollziehen zu können.\n\n```{.callout-note}\n**Lernziele**\n\nDu lernst in dieser Einheit:\n\n- wie du strukturierte CSV-Daten in NumPy-Arrays überführst,\n- wie du fehlende Werte erkennst und ersetzt,\n- wie du typische statistische Kennzahlen berechnest,\n- wie du Daten mit Matplotlib visualisierst,\n- wie du Daten interpolierst und Trends glättest,\n- und wie du reale Anwendungen – z. B. aus dem Bauwesen – analysierst.\n```\n\n# 1. CSV-Dateien: Ein typisches Format für Messdaten\n\nCSV-Dateien („Comma Separated Values“) sind weit verbreitet – etwa für:\n\n- Temperaturverläufe,\n- Messreihen aus Experimenten,\n- Logdaten von Sensoren.\n\nWir beginnen mit einem Beispiel: Temperatur, Luftfeuchtigkeit und CO₂-Werte. Diese Datei enthält auch einige **fehlende Werte**, wie sie in realen Daten oft vorkommen.\n\n```python\nimport numpy as np\ndata = np.genfromtxt(\"beispiel.csv\", delimiter=\",\", skip_header=1)\nprint(data)\n```\n\n# 2. Fehlende Werte erkennen und bereinigen\n\nFehlende Werte werden beim Einlesen als `np.nan` (Not a Number) codiert. Wir zählen zunächst, wie viele Werte fehlen:\n\n```python\nprint(np.isnan(data).sum(axis=0))\n```\n\nUm die Analyse nicht zu verfälschen, ersetzen wir sie – z. B. durch den Mittelwert der Spalte:\n\n```python\nfor i in range(data.shape[1]):\n    mean = np.nanmean(data[:, i])\n    data[:, i] = np.where(np.isnan(data[:, i]), mean, data[:, i])\n```\n\n# 3. Statistische Kennzahlen berechnen\n\nTypische Kennwerte zur Beschreibung von Daten:\n\n- **Mittelwert**: Durchschnitt\n- **Standardabweichung**: Streuung\n- **Minimum und Maximum**\n\n```python\nprint(\"Mittelwerte:\", np.mean(data, axis=0))\nprint(\"Standardabweichung:\", np.std(data, axis=0))\n```\n\n# 4. Daten visualisieren\n\nMit Matplotlib lassen sich Daten übersichtlich darstellen. Wir nutzen z. B. Linien- und Histogrammplots.\n\n```python\nimport matplotlib.pyplot as plt\n\nlabels = [\"Temperatur (°C)\", \"Luftfeuchtigkeit (%)\", \"CO₂ (ppm)\"]\n\nfor i in range(data.shape[1]):\n    plt.plot(data[:, i], label=labels[i])\nplt.legend()\nplt.title(\"Messwerte im Verlauf\")\nplt.grid(True)\nplt.show()\n```\n\n# 5. Interpolation – Lücken schließen\n\nWas tun, wenn Werte fehlen? Interpolation erlaubt uns, **Zwischenwerte zu schätzen**:\n\n```python\nx = np.array([0, 1, 2, 3, 4, 5])\ny = np.array([0, 3, 4, 5, 7, 8])\nx_interp = np.linspace(x.min(), x.max(), 100)\ny_interp = np.interp(x_interp, x, y)\n\nplt.plot(x, y, 'bo', label='Messpunkte')\nplt.plot(x_interp, y_interp, 'r-', label='Interpoliert')\nplt.legend()\nplt.grid(True)\nplt.show()\n```\n\n# 6. Trendglättung – Rauschen reduzieren\n\nVerrauschte Daten? Ein **gleitender Mittelwert** glättet Kurven:\n\n```python\ndata = np.genfromtxt(\"trenddaten_mit_rauschen.csv\", delimiter=\",\", skip_header=1)\nx = data[:, 0]\ny = data[:, 1]\n\nwindow = 5\nweights = np.ones(window) / window\ny_smooth = np.convolve(y, weights, mode='valid')\n\nplt.plot(x, y, label=\"Original\", alpha=0.5)\nplt.plot(x[(window-1)//2:-(window//2)], y_smooth, label=\"Geglättet\", color='red')\nplt.legend()\nplt.grid(True)\nplt.title(\"Trendglättung\")\nplt.show()\n```\n\n# 7. Anwendung: Ballonfahrt-Daten analysieren\n\n```python\nballon = np.genfromtxt(\"messdaten_ballonfahrt.txt\", delimiter=\",\", skip_header=1)\nzeit = ballon[:, 0]\nhoehe = ballon[:, 1]\n\nplt.plot(zeit, hoehe)\nplt.title(\"Ballonfahrt – Höhe über Zeit\")\nplt.xlabel(\"Zeit (s)\")\nplt.ylabel(\"Höhe (m)\")\nplt.grid(True)\nplt.show()\n\ngeschwindigkeit = np.gradient(hoehe, zeit)\nplt.plot(zeit, geschwindigkeit, color=\"orange\")\nplt.title(\"Geschwindigkeit\")\nplt.grid(True)\nplt.show()\n```\n\n# 8. Anwendung: Balkenverformung im Bauingenieurwesen\n\nEin Träger wird in der Mitte belastet. Die Durchbiegung wird an 50 Punkten gemessen:\n\n```python\nbalken = np.genfromtxt(\"balken_durchbiegung.csv\", delimiter=\",\", skip_header=1)\nx = balken[:, 0]\ny = balken[:, 1]\n\nwindow = 7\nweights = np.ones(window) / window\ny_smooth = np.convolve(y, weights, mode='valid')\n\nplt.plot(x, y, label=\"Messung\", alpha=0.5)\nplt.plot(x[(window-1)//2:-(window//2)], y_smooth, label=\"Geglättet\", color='red')\nplt.title(\"Durchbiegung eines Trägers\")\nplt.xlabel(\"Position (m)\")\nplt.ylabel(\"Durchbiegung (mm)\")\nplt.legend()\nplt.grid(True)\nplt.show()\n```\n\n# 9. Zusammenfassung\n\nIn dieser Einheit hast du gelernt:\n\n- wie Daten eingelesen und bereinigt werden,\n- wie man sie analysiert und visualisiert,\n- wie Interpolation und Glättung funktionieren,\n- wie reale Datensätze aus Technik und Naturwissenschaft ausgewertet werden können.\n\nDiese Fähigkeiten sind grundlegend für jede datengetriebene Analyse im Ingenieurbereich.\n\n",
    "supporting": [
      "datenanalyse_files/figure-pdf"
    ],
    "filters": []
  }
}